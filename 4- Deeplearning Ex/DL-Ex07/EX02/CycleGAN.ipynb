{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9bbbf38b-6a64-4344-8a9b-e9ae49c9edc0",
      "metadata": {
        "id": "9bbbf38b-6a64-4344-8a9b-e9ae49c9edc0"
      },
      "source": [
        "## Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36f325d0-aea1-41e8-9f4d-a05f231be29b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36f325d0-aea1-41e8-9f4d-a05f231be29b",
        "outputId": "f5e15485-fb8f-4d93-ca51-849099fcc650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.15.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow keras keras-tuner requests pillow gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77dc05a3-d532-4895-bde5-741fd66a7529",
      "metadata": {
        "id": "77dc05a3-d532-4895-bde5-741fd66a7529"
      },
      "source": [
        "## Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feec34d6-c3ff-4a8d-a05e-b8b96913b18a",
      "metadata": {
        "id": "feec34d6-c3ff-4a8d-a05e-b8b96913b18a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gdown\n",
        "import zipfile\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b550715f-8327-4f7d-845c-8c4601dbe4ba",
      "metadata": {
        "id": "b550715f-8327-4f7d-845c-8c4601dbe4ba"
      },
      "source": [
        "## download dataset and unzipped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "926bec9a-45d4-4dad-8517-d01db963aaf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "926bec9a-45d4-4dad-8517-d01db963aaf9",
        "outputId": "b3b5448a-2163-4400-b3b4-3e53ada28121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0edf0231-4dd9-40c7-b04f-1c3100825e3e",
      "metadata": {
        "id": "0edf0231-4dd9-40c7-b04f-1c3100825e3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e05a53-5c40-4884-a478-cb26c976d5ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-15 20:23:33--  https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\n",
            "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.121.72, 52.219.216.8, 52.219.112.216, ...\n",
            "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.121.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1443490838 (1.3G) [application/zip]\n",
            "Saving to: ‘celeba.zip’\n",
            "\n",
            "celeba.zip          100%[===================>]   1.34G  18.1MB/s    in 78s     \n",
            "\n",
            "2024-07-15 20:24:52 (17.6 MB/s) - ‘celeba.zip’ saved [1443490838/1443490838]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download and extract the celeba dataset\n",
        "# method 1\n",
        "# url = \"https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"\n",
        "# output = \"celeba-dataset.zip\"\n",
        "\n",
        "# if not os.path.exists(output):\n",
        "#     gdown.download(url, output, quiet=False)\n",
        "\n",
        "# if not os.path.exists(\"img_align_celeba\"):\n",
        "#     with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "#         zip_ref.extractall(\"img_align_celeba\")\n",
        "\n",
        "# method 2\n",
        "!wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\n",
        "\n",
        "if not os.path.exists(\"img_align_celeba\"):\n",
        "    with zipfile.ZipFile('celeba.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"img_align_celeba\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and extract cartoonset10k dataset\n",
        "url = \"https://ff236f4f16a03e85267c679ba4dcd9eaff1bb762aad680e328b404c-apidata.googleusercontent.com/download/storage/v1/b/cartoonset_public_files/o/cartoonset10k.tgz?jk=AYBlUPAP02OPNA8fFyd5PCUiRdJxwZPVOKz7EshPPRYzHq_6uyvBgRwHUVVLJRooh8Uq9rfY-bq5rqvQlEiXtNnQsnqrZiRJU0dhm6pe3bpaHA-ITMOg1LVjsQN_RJpF5vjgLxtIAuMH72vb9zUigjAf7pBlhoEOz1IrKG5KbOL7-tAYzfyWwzH4P1PEv3mh_JU3ShmFsXicYq9mVBbL7v0MCpPa-CMfCgS3rvmWW0iz9AKz1g-uMGKha8d7TtVk_FWuWgtRAIpHB7M1Vi9D447OhlbeQ0eur9coeI0uSxLKuw39AlWKdM5eGAui4koenjOognQ5EWn5bYK0VMX0H9j0a4hkSu1pkWO6C32qRFNnpV5Vzz45IW2as3UgttpkHkb7Ma_av3GEz2ShwxCQcdUpKZkQ5ms5FuR4tkv8SgNI1K8QaUoLTmF53R66ZSr2Sj5q2O8dALXsJg64Fmrrxf2EhsC01uXJoQs7PHUZVU7JRwKXL57lF9QRRD64X52szm8OFLJ6VBW_Rq66aUZevR0KsEOYtL02VB5O5PIpUdGuIWQkwBOLpiKeBd5sLrcgVWt6SRbYjfpno2zveWUUHip85iTyRSTVShflV1q2R3umhihkcqLHo2RrbQzKfLaPwQSdmXLMx0kxMZKo-LBk73jU31AmaZLfdibdfAp4KHDdOG4CUYUqdjEKnVlGqi2QjlSwOeNMvvO9wbFJQUShg-FIY21uZ9qVUru06sQfpQbUS9VWSiKJx7E96lP2uHkwdjKXTFLj4PXTsAook9D9HZN43pZN-Vx-IlrQ-zuYdMtYwiuHOZKinnZkslMwSSiHPnE00jLhicJiIny_kcLlHJdd-R9o92-U-KV8yNH-ZPqhAlVQbFjHSWwX9msjZcJpzDbYs5-Vbumnu46lQ0Pk_mNdmJqpANO6VatOrGa_IV7cYBxomu1XTpWnkhZngII-4onHH-0L14FPjwRnwMe61btK1yDsfI-F0nurRot5QrxzSbqdxijd1GoTjDtUK4UNYy-1rqgtbB27KvJFeLOmety-gESsxLWcpz0mtYsmkSwwa2sBb2gs1x5cJFXd4VBBYyrF85a88VGwubSdGOpYp_IuMg2W6dGBWbrOhkcZdt8wdd4dlwNz_owffJYez6Qn-T_Ls-Nx&isca=1\"\n",
        "output = \"cartoonset10k.tgz\"\n",
        "\n",
        "if not os.path.exists(output):\n",
        "    gdown.download(url, output, quiet=False)\n",
        "\n",
        "if not os.path.exists(\"cartoonset10k\"):\n",
        "    with tarfile.open(output) as tar_ref:\n",
        "        tar_ref.extractall('cartoonset10k')"
      ],
      "metadata": {
        "id": "p18Qa8HQnqdT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "1a87fc93-8a8a-43c7-d72d-6039c246a8aa"
      },
      "id": "p18Qa8HQnqdT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://ff236f4f16a03e85267c679ba4dcd9eaff1bb762aad680e328b404c-apidata.googleusercontent.com/download/storage/v1/b/cartoonset_public_files/o/cartoonset10k.tgz?jk=AYBlUPAP02OPNA8fFyd5PCUiRdJxwZPVOKz7EshPPRYzHq_6uyvBgRwHUVVLJRooh8Uq9rfY-bq5rqvQlEiXtNnQsnqrZiRJU0dhm6pe3bpaHA-ITMOg1LVjsQN_RJpF5vjgLxtIAuMH72vb9zUigjAf7pBlhoEOz1IrKG5KbOL7-tAYzfyWwzH4P1PEv3mh_JU3ShmFsXicYq9mVBbL7v0MCpPa-CMfCgS3rvmWW0iz9AKz1g-uMGKha8d7TtVk_FWuWgtRAIpHB7M1Vi9D447OhlbeQ0eur9coeI0uSxLKuw39AlWKdM5eGAui4koenjOognQ5EWn5bYK0VMX0H9j0a4hkSu1pkWO6C32qRFNnpV5Vzz45IW2as3UgttpkHkb7Ma_av3GEz2ShwxCQcdUpKZkQ5ms5FuR4tkv8SgNI1K8QaUoLTmF53R66ZSr2Sj5q2O8dALXsJg64Fmrrxf2EhsC01uXJoQs7PHUZVU7JRwKXL57lF9QRRD64X52szm8OFLJ6VBW_Rq66aUZevR0KsEOYtL02VB5O5PIpUdGuIWQkwBOLpiKeBd5sLrcgVWt6SRbYjfpno2zveWUUHip85iTyRSTVShflV1q2R3umhihkcqLHo2RrbQzKfLaPwQSdmXLMx0kxMZKo-LBk73jU31AmaZLfdibdfAp4KHDdOG4CUYUqdjEKnVlGqi2QjlSwOeNMvvO9wbFJQUShg-FIY21uZ9qVUru06sQfpQbUS9VWSiKJx7E96lP2uHkwdjKXTFLj4PXTsAook9D9HZN43pZN-Vx-IlrQ-zuYdMtYwiuHOZKinnZkslMwSSiHPnE00jLhicJiIny_kcLlHJdd-R9o92-U-KV8yNH-ZPqhAlVQbFjHSWwX9msjZcJpzDbYs5-Vbumnu46lQ0Pk_mNdmJqpANO6VatOrGa_IV7cYBxomu1XTpWnkhZngII-4onHH-0L14FPjwRnwMe61btK1yDsfI-F0nurRot5QrxzSbqdxijd1GoTjDtUK4UNYy-1rqgtbB27KvJFeLOmety-gESsxLWcpz0mtYsmkSwwa2sBb2gs1x5cJFXd4VBBYyrF85a88VGwubSdGOpYp_IuMg2W6dGBWbrOhkcZdt8wdd4dlwNz_owffJYez6Qn-T_Ls-Nx&isca=1\n",
            "To: /content/cartoonset10k.tgz\n",
            "100%|██████████| 68.0/68.0 [00:00<00:00, 274kB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ReadError",
          "evalue": "file could not be opened successfully:\n- method gz: ReadError('not a gzip file')\n- method bz2: ReadError('not a bzip2 file')\n- method xz: ReadError('not an lzma file')\n- method tar: ReadError('truncated header')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReadError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9e3183061c2a>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cartoonset10k\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtar_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cartoonset10k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1802\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m             \u001b[0merror_msgs_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"file could not be opened successfully:\\n{error_msgs_summary}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\":\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadError\u001b[0m: file could not be opened successfully:\n- method gz: ReadError('not a gzip file')\n- method bz2: ReadError('not a bzip2 file')\n- method xz: ReadError('not an lzma file')\n- method tar: ReadError('truncated header')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "695b58ee-6621-4c1d-a063-0fceca04f230",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "695b58ee-6621-4c1d-a063-0fceca04f230",
        "outputId": "24ece428-56b8-4b84-b29c-3d562ab1fee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-15 18:28:55--  https://storage.cloud.google.com/cartoonset_public_files/cartoonset10k.tgz\n",
            "Resolving storage.cloud.google.com (storage.cloud.google.com)... 172.217.203.100, 172.217.203.139, 172.217.203.138, ...\n",
            "Connecting to storage.cloud.google.com (storage.cloud.google.com)|172.217.203.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://accounts.google.com/ServiceLogin?service=cds&passive=1209600&continue=https://storage.cloud.google.com/cartoonset_public_files/cartoonset10k.tgz&followup=https://storage.cloud.google.com/cartoonset_public_files/cartoonset10k.tgz [following]\n",
            "--2024-07-15 18:28:55--  https://accounts.google.com/ServiceLogin?service=cds&passive=1209600&continue=https://storage.cloud.google.com/cartoonset_public_files/cartoonset10k.tgz&followup=https://storage.cloud.google.com/cartoonset_public_files/cartoonset10k.tgz\n",
            "Resolving accounts.google.com (accounts.google.com)... 108.177.11.84, 2607:f8b0:400c:c04::54\n",
            "Connecting to accounts.google.com (accounts.google.com)|108.177.11.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://accounts.google.com/InteractiveLogin?continue=https://storage.cloud.google.com/cartoonset_public_files/cartoonset10k.tgz&followup=https://storage.cloud.google.com/cartoonset_public_files/cartoonset10k.tgz&passive=1209600&service=cds&ifkv=AdF4I77G4DH0Uisn-a43wvNXbgseGJlQwMH7fCkKsYQyT3S9PW2asuKLOzTSNuU3aRGkGUgU9Fu6cw [following]\n",
            "--2024-07-15 18:28:55--  https://accounts.google.com/InteractiveLogin?continue=https://storage.cloud.google.com/cartoonset_public_files/cartoonset10k.tgz&followup=https://storage.cloud.google.com/cartoonset_public_files/cartoonset10k.tgz&passive=1209600&service=cds&ifkv=AdF4I77G4DH0Uisn-a43wvNXbgseGJlQwMH7fCkKsYQyT3S9PW2asuKLOzTSNuU3aRGkGUgU9Fu6cw\n",
            "Reusing existing connection to accounts.google.com:443.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fstorage.cloud.google.com%2Fcartoonset_public_files%2Fcartoonset10k.tgz&followup=https%3A%2F%2Fstorage.cloud.google.com%2Fcartoonset_public_files%2Fcartoonset10k.tgz&ifkv=AdF4I75EASYUDEt2lrLa2UrkehvTVGInH8FQ1xL8QE8ZFIhUMgbaTDPN1M4CHAelsZzFvnFoVhml-g&passive=1209600&service=cds&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S-1023053851%3A1721068135420401 [following]\n",
            "--2024-07-15 18:28:55--  https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fstorage.cloud.google.com%2Fcartoonset_public_files%2Fcartoonset10k.tgz&followup=https%3A%2F%2Fstorage.cloud.google.com%2Fcartoonset_public_files%2Fcartoonset10k.tgz&ifkv=AdF4I75EASYUDEt2lrLa2UrkehvTVGInH8FQ1xL8QE8ZFIhUMgbaTDPN1M4CHAelsZzFvnFoVhml-g&passive=1209600&service=cds&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S-1023053851%3A1721068135420401\n",
            "Reusing existing connection to accounts.google.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘cartoonset10k.tgz’\n",
            "\n",
            "cartoonset10k.tgz       [ <=>                ] 168.52K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-07-15 18:28:55 (1.16 MB/s) - ‘cartoonset10k.tgz’ saved [172566]\n",
            "\n",
            "\n",
            "gzip: stdin: not in gzip format\n",
            "tar: Child returned status 1\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ],
      "source": [
        "# Load and extract cartoonset10k dataset\n",
        "# link=\"https://storage.cloud.google.com/cartoonset_public_files/cartoonset10k.tgz\"\n",
        "# !wget -O cartoonset10k.tgz $link\n",
        "# !tar -xvzf cartoonset10k.tgz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load from drive and extract cartoonset10k dataset\n",
        "path = '/content/drive/MyDrive/cartoonset10k.tgz'\n",
        "if not os.path.exists(\"cartoonset10k\"):\n",
        "    with tarfile.open(path) as tar_ref:\n",
        "        tar_ref.extractall('cartoonset10k')"
      ],
      "metadata": {
        "id": "mN1chXxkEUWR"
      },
      "id": "mN1chXxkEUWR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls -l \"./cartoonset10k/cartoonset10k/\" | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7AeeSg4Eu9F",
        "outputId": "e2bcaf9f-eedd-4b32-d574-8bbfaf67ca0f"
      },
      "id": "D7AeeSg4Eu9F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -l \"./img_align_celeba/img_align_celeba/\" | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rkAOFeiEz2R",
        "outputId": "e689d130-c4b6-437b-b835-566d5665ad4d"
      },
      "id": "1rkAOFeiEz2R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03dc3991-d741-4ede-8f81-c6d86e47fead",
      "metadata": {
        "id": "03dc3991-d741-4ede-8f81-c6d86e47fead"
      },
      "outputs": [],
      "source": [
        "# Define paths for the dataset\n",
        "cartoon_data_dir = \"./cartoonset10k/cartoonset10k/\"\n",
        "celeba_data_dir = \"./img_align_celeba/img_align_celeba/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "689a80b9-3ce9-4341-83bf-c6dd31058c42",
      "metadata": {
        "id": "689a80b9-3ce9-4341-83bf-c6dd31058c42"
      },
      "outputs": [],
      "source": [
        "# Preprocess the dataset\n",
        "def preprocess_image(image):\n",
        "    image = tf.image.resize(image, (256, 256))\n",
        "    image = (image - 127.5) / 127.5  # Normalize to [-1, 1]\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f033e21-1b67-4b13-981f-e2244e53ef49",
      "metadata": {
        "id": "7f033e21-1b67-4b13-981f-e2244e53ef49"
      },
      "outputs": [],
      "source": [
        "def load_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_image(image, channels=3)\n",
        "    return preprocess_image(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "902f8466-e468-490e-a7ab-e748326fe54f",
      "metadata": {
        "id": "902f8466-e468-490e-a7ab-e748326fe54f"
      },
      "outputs": [],
      "source": [
        "def load_dataset(data_dir):\n",
        "    # batch_size = 64\n",
        "    # buffer_size = 60000\n",
        "    image_paths = []\n",
        "    for file in os.listdir(data_dir):\n",
        "        if file.endswith(\".png\") or file.endswith(\".jpg\"):\n",
        "            image_paths.append(os.path.join(data_dir, file))\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "    dataset = dataset.map(lambda image_path: load_image(image_path), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    # dataset = dataset.shuffle(buffer_size).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(1)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEW LOADER"
      ],
      "metadata": {
        "id": "sGGyTHdUFZ85"
      },
      "id": "sGGyTHdUFZ85"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(data_dir, batch_size=64, buffer_size=60000, repeat_factor=20):\n",
        "    image_paths = []\n",
        "    for file in os.listdir(data_dir):\n",
        "        if file.endswith(\".png\") or file.endswith(\".jpg\"):\n",
        "            image_paths.append(os.path.join(data_dir, file))\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "    dataset = dataset.map(lambda image_path: load_image(image_path), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.shuffle(buffer_size).repeat(repeat_factor).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "O6ex1h2qFIP4"
      },
      "id": "O6ex1h2qFIP4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8357f85e-bf3a-48ed-9f8b-1eec2fe4bbd8",
      "metadata": {
        "id": "8357f85e-bf3a-48ed-9f8b-1eec2fe4bbd8"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "cartoon_dataset = load_dataset(cartoon_data_dir)\n",
        "celeba_dataset = load_dataset(celeba_data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7f7425e-3c45-44c6-9c15-979fad94f2a5",
      "metadata": {
        "id": "f7f7425e-3c45-44c6-9c15-979fad94f2a5"
      },
      "source": [
        "## Define the CycleGAN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c38d4197-c00c-4499-92b8-abaacb198226",
      "metadata": {
        "id": "c38d4197-c00c-4499-92b8-abaacb198226"
      },
      "outputs": [],
      "source": [
        "def build_generator():\n",
        "    inputs = layers.Input(shape=(256, 256, 3))\n",
        "\n",
        "    # Encoder\n",
        "    x = layers.Conv2D(64, kernel_size=7, strides=1, padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(256, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # Bottleneck with residual blocks\n",
        "    for _ in range(9):\n",
        "        res = x\n",
        "        x = layers.Conv2D(256, kernel_size=3, strides=1, padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.ReLU()(x)\n",
        "        x = layers.Conv2D(256, kernel_size=3, strides=1, padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Add()([x, res])\n",
        "\n",
        "    # Decoder\n",
        "    x = layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    outputs = layers.Conv2D(3, kernel_size=7, strides=1, padding='same', activation='tanh')(x)\n",
        "\n",
        "    return models.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58088c2a-1346-4fb3-ac2c-2a0f660c278b",
      "metadata": {
        "id": "58088c2a-1346-4fb3-ac2c-2a0f660c278b"
      },
      "outputs": [],
      "source": [
        "def build_discriminator():\n",
        "    inputs = layers.Input(shape=(256, 256, 3))\n",
        "\n",
        "    x = layers.Conv2D(64, kernel_size=4, strides=2, padding='same')(inputs)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "    x = layers.Conv2D(128, kernel_size=4, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "    x = layers.Conv2D(256, kernel_size=4, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "    x = layers.Conv2D(512, kernel_size=4, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "    outputs = layers.Conv2D(1, kernel_size=4, strides=1, padding='same', activation='sigmoid')(x)\n",
        "\n",
        "    return models.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3367b2b7-e733-449e-858d-b113fcc28034",
      "metadata": {
        "id": "3367b2b7-e733-449e-858d-b113fcc28034"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "upmW8-7jAPRz"
      },
      "id": "upmW8-7jAPRz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch a real image from the \"thispersondoesnotexist\" website\n",
        "def fetch_image_from_thispersondoesnotexist():\n",
        "    response = requests.get(\"https://thispersondoesnotexist.com\")\n",
        "    img = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "    img = img.resize((256, 256))\n",
        "    img = np.array(img) / 127.5 - 1\n",
        "    return np.expand_dims(img, axis=0)"
      ],
      "metadata": {
        "id": "zY0V89RQAQo0"
      },
      "id": "zY0V89RQAQo0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3293b0f3-a345-4452-918b-fa5b4f498ed9",
      "metadata": {
        "id": "3293b0f3-a345-4452-918b-fa5b4f498ed9"
      },
      "outputs": [],
      "source": [
        "# Define the CycleGAN training loop\n",
        "def train_cyclegan(generator_G, generator_F, discriminator_X, discriminator_Y, cartoon_dataset, real_dataset, epochs, batch_size, checkpoint_dir):\n",
        "    # Define the optimizers\n",
        "    gen_G_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    gen_F_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    disc_X_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    disc_Y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "    # Define the loss functions\n",
        "    loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    LAMBDA = 10\n",
        "\n",
        "    def generator_loss(fake_output):\n",
        "        return loss_obj(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "    def discriminator_loss(real_output, fake_output):\n",
        "        real_loss = loss_obj(tf.ones_like(real_output), real_output)\n",
        "        fake_loss = loss_obj(tf.zeros_like(fake_output), fake_output)\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "    def calc_cycle_loss(real_image, cycled_image):\n",
        "        loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
        "        return LAMBDA * loss\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(real_x, real_y):\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            fake_y = generator_G(real_x, training=True)\n",
        "            cycled_x = generator_F(fake_y, training=True)\n",
        "\n",
        "            fake_x = generator_F(real_y, training=True)\n",
        "            cycled_y = generator_G(fake_x, training=True)\n",
        "\n",
        "            same_y = generator_G(real_y, training=True)\n",
        "            same_x = generator_F(real_x, training=True)\n",
        "\n",
        "            disc_real_x = discriminator_X(real_x, training=True)\n",
        "            disc_real_y = discriminator_Y(real_y, training=True)\n",
        "\n",
        "            disc_fake_x = discriminator_X(fake_x, training=True)\n",
        "            disc_fake_y = discriminator_Y(fake_y, training=True)\n",
        "\n",
        "            gen_G_loss = generator_loss(disc_fake_y) + calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
        "            gen_F_loss = generator_loss(disc_fake_x) + calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
        "\n",
        "            disc_X_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
        "            disc_Y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
        "\n",
        "        gradients_gen_G = tape.gradient(gen_G_loss, generator_G.trainable_variables)\n",
        "        gradients_gen_F = tape.gradient(gen_F_loss, generator_F.trainable_variables)\n",
        "        gradients_disc_X = tape.gradient(disc_X_loss, discriminator_X.trainable_variables)\n",
        "        gradients_disc_Y = tape.gradient(disc_Y_loss, discriminator_Y.trainable_variables)\n",
        "\n",
        "        gen_G_optimizer.apply_gradients(zip(gradients_gen_G, generator_G.trainable_variables))\n",
        "        gen_F_optimizer.apply_gradients(zip(gradients_gen_F, generator_F.trainable_variables))\n",
        "        disc_X_optimizer.apply_gradients(zip(gradients_disc_X, discriminator_X.trainable_variables))\n",
        "        disc_Y_optimizer.apply_gradients(zip(gradients_disc_Y, discriminator_Y.trainable_variables))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for real_x, real_y in tf.data.Dataset.zip((real_dataset, cartoon_dataset)):\n",
        "            train_step(real_x, real_y)\n",
        "\n",
        "        # Save the model every epoch\n",
        "        generator_G.save(os.path.join(checkpoint_dir, f'generator_G_epoch_{epoch+1}.h5'))\n",
        "        generator_F.save(os.path.join(checkpoint_dir, f'generator_F_epoch_{epoch+1}.h5'))\n",
        "\n",
        "        # Test the generator model with a real image from thispersondoesnotexist\n",
        "        test_image = fetch_image_from_thispersondoesnotexist()\n",
        "        cartoonized_image = generator_G(test_image, training=False)\n",
        "\n",
        "        # Show the real and cartoonized images side by side\n",
        "        display_images(test_image, cartoonized_image, epoch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(real_image, cartoonized_image, epoch):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "    axs[0].imshow((real_image[0] + 1) / 2)\n",
        "    axs[0].set_title('Real Image')\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    axs[1].imshow((cartoonized_image[0] + 1) / 2)\n",
        "    axs[1].set_title('Cartoonized Image')\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "    plt.savefig(f'cartoonized_epoch_{epoch+1}.png')"
      ],
      "metadata": {
        "id": "rwgBcm90_wgs"
      },
      "id": "rwgBcm90_wgs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the models\n",
        "generator_G = build_generator()\n",
        "generator_F = build_generator()\n",
        "discriminator_X = build_discriminator()\n",
        "discriminator_Y = build_discriminator()"
      ],
      "metadata": {
        "id": "hi3xV-VwAL8M"
      },
      "id": "hi3xV-VwAL8M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEW SECTION"
      ],
      "metadata": {
        "id": "U9kJ05faEjLL"
      },
      "id": "U9kJ05faEjLL"
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss functions and optimizers\n",
        "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = loss_obj(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = loss_obj(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return loss_obj(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "LAMBDA = 10\n",
        "\n",
        "def cycle_consistency_loss(real_image, cycled_image):\n",
        "    return LAMBDA * tf.reduce_mean(tf.abs(real_image - cycled_image))"
      ],
      "metadata": {
        "id": "ko_0GeWFEo2V"
      },
      "id": "ko_0GeWFEo2V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training step\n",
        "@tf.function\n",
        "def train_step(real_x, real_y):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        fake_y = generator_G(real_x, training=True)\n",
        "        cycled_x = generator_F(fake_y, training=True)\n",
        "        fake_x = generator_F(real_y, training=True)\n",
        "        cycled_y = generator_G(fake_x, training=True)\n",
        "\n",
        "        same_x = generator_F(real_x, training=True)\n",
        "        same_y = generator_G(real_y, training=True)\n",
        "\n",
        "        disc_real_x = discriminator_X(real_x, training=True)\n",
        "        disc_real_y = discriminator_Y(real_y, training=True)\n",
        "        disc_fake_x = discriminator_X(fake_x, training=True)\n",
        "        disc_fake_y = discriminator_Y(fake_y, training=True)\n",
        "\n",
        "        gen_G_loss = generator_loss(disc_fake_y)\n",
        "        gen_F_loss = generator_loss(disc_fake_x)\n",
        "        total_cycle_loss = cycle_consistency_loss(real_x, cycled_x) + cycle_consistency_loss(real_y, cycled_y)\n",
        "        total_gen_G_loss = gen_G_loss + total_cycle_loss + 0.5 * loss_obj(real_x, same_x)\n",
        "        total_gen_F_loss = gen_F_loss + total_cycle_loss + 0.5 * loss_obj(real_y, same_y)\n",
        "\n",
        "        disc_X_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
        "        disc_Y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
        "\n",
        "    gradients_of_gen_G = tape.gradient(total_gen_G_loss, generator_G.trainable_variables)\n",
        "    gradients_of_gen_F = tape.gradient(total_gen_F_loss, generator_F.trainable_variables)\n",
        "    gradients_of_disc_X = tape.gradient(disc_X_loss, discriminator_X.trainable_variables)\n",
        "    gradients_of_disc_Y = tape.gradient(disc_Y_loss, discriminator_Y.trainable_variables)\n",
        "\n",
        "    gen_G_optimizer.apply_gradients(zip(gradients_of_gen_G, generator_G.trainable_variables))\n",
        "    gen_F_optimizer.apply_gradients(zip(gradients_of_gen_F, generator_F.trainable_variables))\n",
        "    disc_X_optimizer.apply_gradients(zip(gradients_of_disc_X, discriminator_X.trainable_variables))\n",
        "    disc_Y_optimizer.apply_gradients(zip(gradients_of_disc_Y, discriminator_Y.trainable_variables))\n",
        "\n",
        "# Training loop\n",
        "def train_cyclegan(generator_G, generator_F, discriminator_X, discriminator_Y, cartoon_dataset, celeba_dataset, epochs, batch_size, checkpoint_dir):\n",
        "    gen_G_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    gen_F_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    disc_X_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    disc_Y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for real_x, real_y in tf.data.Dataset.zip((celeba_dataset, cartoon_dataset)):\n",
        "            train_step(real_x, real_y)\n",
        "\n",
        "        print(f'Time taken for epoch {epoch + 1} is {time.time() - start:.4f} sec')\n",
        "\n",
        "        # Save the model every epoch\n",
        "        generator_G.save(os.path.join(checkpoint_dir, f'generator_G_epoch_{epoch + 1}.h5'))\n",
        "        generator_F.save(os.path.join(checkpoint_dir, f'generator_F_epoch_{epoch + 1}.h5'))\n",
        "\n",
        "        # Test the model with a new image\n",
        "        test_real_image = fetch_image_from_thispersondoesnotexist()\n",
        "        test_cartoon_image = generator_G.predict(test_real_image[np.newaxis, ...])[0]\n",
        "\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title('Real Image')\n",
        "        plt.imshow((test_real_image + 1) / 2)\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title('Cartoonized Image')\n",
        "        plt.imshow((test_cartoon_image + 1) / 2)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "hY_YMaoWECWQ"
      },
      "id": "hY_YMaoWECWQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters and directories\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "checkpoint_dir = '/content/drive/MyDrive/cyclegan_training/checkpoints'\n",
        "\n",
        "# Train the CycleGAN\n",
        "train_cyclegan(generator_G, generator_F, discriminator_X, discriminator_Y, cartoon_dataset, celeba_dataset, epochs=3, batch_size=1, checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R7Y9_EcAJhT",
        "outputId": "87a53587-f8b9-4080-d399-638f78152f1b"
      },
      "id": "7R7Y9_EcAJhT",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nLVsCT7YCQ_T"
      },
      "id": "nLVsCT7YCQ_T",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}