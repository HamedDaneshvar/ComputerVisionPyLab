{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39ec4b06-82c4-4090-a629-d6f1042736c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa5e7a-73ee-4cc5-8ea8-856ad7f66b55",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6353387-4da1-4552-bd4d-36bea3dcf3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video file\n",
    "video = cv2.VideoCapture('media/lane.mp4')\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    frame_count += 1\n",
    "    \n",
    "    if frame_count == 8:\n",
    "        # cv2.imshow('8th Frame', frame)\n",
    "        # cv2.waitKey(0)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2c858c8f-3670-4ace-a1d2-5bf57d8ec55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert colorful frame to gray\n",
    "gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15ccd92d-83dc-47b2-8cf2-54a81076b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoising and find edges\n",
    "gaussian_img = cv2.GaussianBlur(gray_frame, (5, 5), 0)\n",
    "edges = cv2.Canny(gaussian_img, 120, 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e79aac76-8e64-4ffb-b451-c582bc8dd9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the edges on the original image\n",
    "output = frame.copy()\n",
    "output[edges != 0] = [255, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33d23fd5-48e0-4f01-bc26-4c15b90932e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and show the result\n",
    "_ = cv2.imwrite('detected_edges_frame.png', output)\n",
    "cv2.imshow('detected_edges', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc80845-b0a0-4192-8b9e-a204c2dad7b8",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fc68aecb-0ffa-4f66-abbc-43bc89776980",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('IMG1.jpg', cv2.IMREAD_ANYCOLOR)\n",
    "img2 = cv2.imread('IMG2.jpg', cv2.IMREAD_ANYCOLOR)\n",
    "\n",
    "img1 = cv2.resize(img1, (int(img1.shape[1]*0.4), int(img1.shape[0]*0.4)))\n",
    "img2 = cv2.resize(img2, (int(img2.shape[1]*0.4), int(img2.shape[0]*0.4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125850a9-6350-4dbf-a03c-11db19223162",
   "metadata": {},
   "source": [
    "### color mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "55c5d2ec-cf63-44d9-8e0a-14099360e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "\n",
    "keypoint1, descriptor1 = sift.detectAndCompute(img1, mask=None)\n",
    "keypoint2, descriptor2 = sift.detectAndCompute(img2, mask=None)\n",
    "\n",
    "img1_kp = cv2.drawKeypoints(img1, keypoint1, 0, (255, 0, 0), flags= cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "img2_kp = cv2.drawKeypoints(img2, keypoint2, 0, (255, 0, 0), flags= cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Brute force\n",
    "bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "matches = bf.match(descriptor1, descriptor2)\n",
    "\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "\n",
    "result = cv2.drawMatches(img1, keypoint1, img2, keypoint2, matches[:50], None)\n",
    "\n",
    "_ = cv2.imwrite('sift_color_mode.jpg', result)\n",
    "\n",
    "result = cv2.resize(result, (int(result.shape[1]*0.4), int(result.shape[0]*0.4)))\n",
    "cv2.imshow('sift_color_mode', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e018d96-9b47-41ac-9ac2-f31c0701bb88",
   "metadata": {},
   "source": [
    "### gray mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ea4dd0a3-bd58-47ad-a1cf-08f6bdd9980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to gray\n",
    "gray_img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray_img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "\n",
    "keypoint1, descriptor1 = sift.detectAndCompute(gray_img1, mask=None)\n",
    "keypoint2, descriptor2 = sift.detectAndCompute(gray_img2, mask=None)\n",
    "\n",
    "img1_kp = cv2.drawKeypoints(gray_img1, keypoint1, 0, (255, 0, 0), flags= cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "img2_kp = cv2.drawKeypoints(gray_img2, keypoint2, 0, (255, 0, 0), flags= cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Brute force\n",
    "bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "matches = bf.match(descriptor1, descriptor2)\n",
    "\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "\n",
    "result = cv2.drawMatches(img1, keypoint1, img2, keypoint2, matches[:50], None)\n",
    "_ = cv2.imwrite('sift_gray_mode.jpg', result)\n",
    "\n",
    "result = cv2.resize(result, (int(result.shape[1]*0.4), int(result.shape[0]*0.4)))\n",
    "cv2.imshow('sift_color_mode', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
